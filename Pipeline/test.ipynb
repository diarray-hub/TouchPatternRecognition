{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and preprocessing\n",
    "\n",
    "Import functions and libraries we need to load the model and preprocess test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-12 16:08:31.247301: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-05-12 16:08:31.248839: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-12 16:08:31.277185: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-12 16:08:31.277710: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-12 16:08:31.732242: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from train.preprocessing import stats_summary\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[202.14529915,  88.92186765,  65.        , ...,   3.14159265,\n",
      "          6.23322691,   1.9849999 ],\n",
      "       [169.85714286,  96.61313906,  42.        , ...,   3.14159265,\n",
      "          6.23973441,   2.83199978],\n",
      "       [229.96638655,  86.54575054,  45.        , ...,   3.14159265,\n",
      "          5.72458599,   2.02899981],\n",
      "       ...,\n",
      "       [163.18181818, 102.76302676,  39.        , ...,   3.14159265,\n",
      "          6.23776203,   1.32400012],\n",
      "       [ 76.71428571,  27.14229323,  40.5       , ...,   2.55359005,\n",
      "          3.33898821,   0.54100013],\n",
      "       [218.24626866,  56.44799305, 155.5       , ...,   3.14159265,\n",
      "          6.24748619,   1.17400002]]), array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))\n"
     ]
    }
   ],
   "source": [
    "userdata = stats_summary(paths=[\"test_data/user.json\"], label=1)\n",
    "mine = stats_summary(paths=[\"test_data/others.json\"], label=0)\n",
    "training_data = (np.concatenate((userdata[0], mine[0])), np.concatenate((userdata[1], mine[1])))\n",
    "print(training_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model and Test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2521 - accuracy: 0.9000\n",
      "loss: 0.2520941495895386, accuracy: 0.8999999761581421\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"../Models/mymy.log/\")\n",
    "loss, acc = model.evaluate(training_data[0], training_data[1])\n",
    "print(f\"loss: {loss}, accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_71 (Dense)            (None, 21)                462       \n",
      "                                                                 \n",
      " dense_72 (Dense)            (None, 10)                220       \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 693\n",
      "Trainable params: 693\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 12ms/step\n",
      "Welcome User\n"
     ]
    }
   ],
   "source": [
    "enrty = training_data[0][23].reshape((1, 21))\n",
    "out = model.predict(enrty)\n",
    "print(\"Welcome User\") if out[0][0] >= 0.95 else print(\"Not Recognized\") # Note that to use such a system for authentcation the threshold should be at least 99%"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save in TF.js layer format\n",
    "\n",
    "We are going to save the model in this format in order to load and use it in the app\n",
    "\n",
    "Note that all libraries we used can be installed by pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflowjs as tfjs\n",
    "tfjs_target_dir = \"../Models/tfjs_model\"\n",
    "tfjs.converters.save_keras_model(model, tfjs_target_dir) # Note that if we had saved the model in .H5 file we would be able to use the tensorflowjs_converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
